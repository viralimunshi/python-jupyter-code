{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06b5fabb",
   "metadata": {},
   "source": [
    "# CS 617 - Data Mining\n",
    "\n",
    "## Homework 2 - Problem 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0d1825c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from IPython.display import display, HTML, Math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28715f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to load in our dataset. Don't worry about what it's doing.\n",
    "np.random.seed(25)\n",
    "\n",
    "salaries_raw = pd.read_csv('data_scientist_salaries-1.csv')\n",
    "salaries = salaries_raw.get(['YearsCodingProf', 'Age', 'FormalEducation', 'Salary']).dropna()\n",
    "\n",
    "def extract_years(year_str):\n",
    "    if isinstance(year_str, float):\n",
    "        return year_str\n",
    "    if 'older' in year_str:\n",
    "        years = 65\n",
    "    elif 'more' in year_str:\n",
    "        years = 30\n",
    "    elif 'Under' in year_str:\n",
    "        years = 18\n",
    "    else:\n",
    "        extracted = re.findall('\\d+', year_str)\n",
    "        try:\n",
    "            lower, upper = int(extracted[0]), int(extracted[1])\n",
    "        except:\n",
    "            print(extracted)\n",
    "        years = np.random.randint(lower, upper + 1)\n",
    "    return years + np.round(np.random.normal(0, 1), 2)\n",
    "\n",
    "salaries['Age'] = salaries['Age'].apply(extract_years)\n",
    "salaries['YearsExperience'] = salaries['YearsCodingProf'].apply(extract_years)\n",
    "salaries = salaries[['YearsExperience', 'Age', 'FormalEducation', 'Salary']]\n",
    "salaries = salaries[(salaries['Salary'] < 500000) & (salaries['Salary'] > 1000) & (salaries['YearsExperience'] > 0)].reset_index(drop=True)\n",
    "salaries['Salary'] /= 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ecd01a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YearsExperience</th>\n",
       "      <th>Age</th>\n",
       "      <th>FormalEducation</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.37</td>\n",
       "      <td>28.39</td>\n",
       "      <td>Master’s degree (MA, MS, M.Eng., MBA, etc.)</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.35</td>\n",
       "      <td>25.78</td>\n",
       "      <td>Some college/university study without earning ...</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.05</td>\n",
       "      <td>31.04</td>\n",
       "      <td>Bachelor’s degree (BA, BS, B.Eng., etc.)</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.48</td>\n",
       "      <td>38.78</td>\n",
       "      <td>Bachelor’s degree (BA, BS, B.Eng., etc.)</td>\n",
       "      <td>185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.95</td>\n",
       "      <td>33.45</td>\n",
       "      <td>Master’s degree (MA, MS, M.Eng., MBA, etc.)</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>5.07</td>\n",
       "      <td>25.55</td>\n",
       "      <td>Master’s degree (MA, MS, M.Eng., MBA, etc.)</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>8.24</td>\n",
       "      <td>30.54</td>\n",
       "      <td>Associate degree</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>6.46</td>\n",
       "      <td>32.91</td>\n",
       "      <td>Other doctoral degree (Ph.D, Ed.D., etc.)</td>\n",
       "      <td>149.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>16.27</td>\n",
       "      <td>64.55</td>\n",
       "      <td>Master’s degree (MA, MS, M.Eng., MBA, etc.)</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>0.56</td>\n",
       "      <td>38.32</td>\n",
       "      <td>Professional degree (JD, MD, etc.)</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>988 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     YearsExperience    Age  \\\n",
       "0               6.37  28.39   \n",
       "1               0.35  25.78   \n",
       "2               4.05  31.04   \n",
       "3              18.48  38.78   \n",
       "4               4.95  33.45   \n",
       "..               ...    ...   \n",
       "983             5.07  25.55   \n",
       "984             8.24  30.54   \n",
       "985             6.46  32.91   \n",
       "986            16.27  64.55   \n",
       "987             0.56  38.32   \n",
       "\n",
       "                                       FormalEducation  Salary  \n",
       "0          Master’s degree (MA, MS, M.Eng., MBA, etc.)   120.0  \n",
       "1    Some college/university study without earning ...   120.0  \n",
       "2             Bachelor’s degree (BA, BS, B.Eng., etc.)    70.0  \n",
       "3             Bachelor’s degree (BA, BS, B.Eng., etc.)   185.0  \n",
       "4          Master’s degree (MA, MS, M.Eng., MBA, etc.)   125.0  \n",
       "..                                                 ...     ...  \n",
       "983        Master’s degree (MA, MS, M.Eng., MBA, etc.)    27.0  \n",
       "984                                   Associate degree   120.0  \n",
       "985          Other doctoral degree (Ph.D, Ed.D., etc.)   149.0  \n",
       "986        Master’s degree (MA, MS, M.Eng., MBA, etc.)    57.0  \n",
       "987                 Professional degree (JD, MD, etc.)    50.0  \n",
       "\n",
       "[988 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504cc265",
   "metadata": {},
   "source": [
    "### Design matrix\n",
    "\n",
    "In this case, we only have one feature – `'YearsExperience'`. Our design matrix would then look something like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15e1b13f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>YearsExperience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>18.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>1</td>\n",
       "      <td>5.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>1</td>\n",
       "      <td>8.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>1</td>\n",
       "      <td>6.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>1</td>\n",
       "      <td>16.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>1</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>988 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     1  YearsExperience\n",
       "0    1             6.37\n",
       "1    1             0.35\n",
       "2    1             4.05\n",
       "3    1            18.48\n",
       "4    1             4.95\n",
       "..  ..              ...\n",
       "983  1             5.07\n",
       "984  1             8.24\n",
       "985  1             6.46\n",
       "986  1            16.27\n",
       "987  1             0.56\n",
       "\n",
       "[988 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Don't worry about this code ---\n",
    "X_as_df = pd.DataFrame()\n",
    "X_as_df['1'] = np.ones(salaries.shape[0]).astype(int)\n",
    "X_as_df['YearsExperience'] = salaries['YearsExperience']\n",
    "X_as_df\n",
    "# ---\n",
    "\n",
    "X_as_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69dc16cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.  ,  6.37],\n",
       "       [ 1.  ,  0.35],\n",
       "       [ 1.  ,  4.05],\n",
       "       ...,\n",
       "       [ 1.  ,  6.46],\n",
       "       [ 1.  , 16.27],\n",
       "       [ 1.  ,  0.56]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting to a numpy array\n",
    "X = X_as_df.values\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb6fe71",
   "metadata": {},
   "source": [
    "This is the design matrix! ^"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ff69f9",
   "metadata": {},
   "source": [
    "### Observation vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a1e07d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      120.0\n",
       "1      120.0\n",
       "2       70.0\n",
       "3      185.0\n",
       "4      125.0\n",
       "       ...  \n",
       "983     27.0\n",
       "984    120.0\n",
       "985    149.0\n",
       "986     57.0\n",
       "987     50.0\n",
       "Name: Salary, Length: 988, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = salaries['Salary']\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e683e02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([120.    , 120.    ,  70.    , 185.    , 125.    , 113.    ,\n",
       "        83.    ,  40.    , 300.    ,  60.    , 130.    ,  60.    ,\n",
       "       120.    , 102.    ,  80.    , 120.    , 115.    ,  65.    ,\n",
       "        75.    , 149.    , 100.    , 150.    , 135.    , 115.    ,\n",
       "       125.    ,   9.8   ,  80.    ,  92.    ,  52.    , 145.    ,\n",
       "       120.    , 137.    , 200.    , 140.    , 115.    , 180.    ,\n",
       "       130.    , 145.    ,  72.    , 135.    ,  90.    , 160.    ,\n",
       "        78.    , 120.    , 152.    , 152.    , 140.    , 100.    ,\n",
       "       130.    , 100.    , 115.    , 137.    , 100.    , 106.    ,\n",
       "        80.    , 104.    ,  89.    ,  83.    , 189.    , 158.    ,\n",
       "       105.    ,  90.    ,  13.3   , 135.    ,  70.    , 155.    ,\n",
       "       115.    ,  57.6   , 206.    , 130.    , 182.    ,  32.    ,\n",
       "       116.    , 245.    ,  45.    ,  74.    , 100.    , 220.    ,\n",
       "       100.    ,  82.    ,  40.    , 150.    , 147.    ,  70.    ,\n",
       "       103.    ,  90.    ,  80.    ,  61.    ,  80.    , 105.    ,\n",
       "        80.    ,  95.    ,  93.    ,  75.    ,  50.    , 116.    ,\n",
       "        55.    , 115.    , 147.    ,  80.    , 200.    ,  54.    ,\n",
       "        65.    ,  70.    ,  30.    , 100.    ,  79.    ,  74.    ,\n",
       "        90.    , 110.    ,  90.    , 110.    , 100.    , 145.    ,\n",
       "        66.    ,  24.    , 150.    ,  45.    , 102.    , 150.    ,\n",
       "       150.    ,  90.    , 140.    ,  95.    , 110.    ,  70.    ,\n",
       "        98.    , 122.    , 117.    ,  70.    ,   5.3   ,  74.5   ,\n",
       "       160.    , 100.    , 125.    , 115.    , 400.    , 122.    ,\n",
       "        78.3   , 130.    , 200.    , 125.    ,   5.    ,  79.    ,\n",
       "         6.3   ,  53.    ,  78.    , 132.    ,  88.    , 103.    ,\n",
       "        70.    , 180.    ,  90.    ,  77.    , 160.    , 118.    ,\n",
       "       113.    ,   2.    , 140.    ,  58.    ,  68.    ,  90.    ,\n",
       "       175.    , 111.    , 168.    , 123.    , 160.    , 105.    ,\n",
       "        90.    ,  10.    ,  85.    , 170.    ,  54.    , 125.    ,\n",
       "       161.    ,  70.    ,  87.    ,  60.    ,  70.    , 100.    ,\n",
       "       105.    ,  75.    ,  78.    , 104.    , 112.    , 170.    ,\n",
       "        65.    , 115.    ,  90.    , 125.    , 155.    , 120.    ,\n",
       "        87.    ,  90.    ,  85.    , 110.    , 140.    , 110.    ,\n",
       "       103.    ,  97.5   , 150.    ,  75.5   , 180.    , 120.    ,\n",
       "       150.    , 195.    , 170.    , 155.    ,  14.326 , 120.    ,\n",
       "       100.    , 450.    ,  70.064 ,  80.    , 105.    ,  84.    ,\n",
       "       180.    , 130.    , 110.    ,  84.    , 186.    , 136.    ,\n",
       "       105.475 , 145.    , 120.    , 150.    ,  75.    , 135.    ,\n",
       "        70.    , 150.    , 100.    ,  85.    , 305.    ,  96.    ,\n",
       "       125.    ,  19.    , 162.    , 146.    , 100.    ,  80.    ,\n",
       "        94.5   , 240.    ,  61.    ,  81.    , 194.    , 105.    ,\n",
       "        72.    , 150.    , 130.    ,  90.    ,  75.    , 105.    ,\n",
       "       154.    ,  17.5   , 205.    ,   4.1   ,  75.    , 115.    ,\n",
       "        85.    ,  80.    , 116.    ,  85.    ,  35.    , 195.    ,\n",
       "       120.524 , 120.    , 100.    , 177.    , 120.    , 135.441 ,\n",
       "         2.2   ,  80.    ,  92.    ,  70.    , 115.    ,  80.    ,\n",
       "       135.    , 125.    ,  30.    , 175.    ,  95.    ,  63.    ,\n",
       "        79.    ,  65.    , 125.    , 280.    ,  90.    ,  81.    ,\n",
       "       140.    , 110.    , 103.5   ,   2.6   ,  80.    , 120.    ,\n",
       "       135.    , 160.    , 135.    , 160.    , 167.    , 152.74  ,\n",
       "       207.    ,  85.    ,  88.    , 120.    ,  80.    ,  81.    ,\n",
       "       160.    ,  70.    ,  90.    ,  90.    , 225.    ,  70.    ,\n",
       "        63.    ,  70.    ,  97.    ,  11.    ,  50.    , 115.    ,\n",
       "        55.    , 127.    ,  85.    , 182.5   , 150.    , 145.    ,\n",
       "       130.    ,  80.    , 126.    ,  75.    , 120.    , 165.    ,\n",
       "       100.    , 185.    ,  94.    ,  73.    ,  99.    ,  90.    ,\n",
       "       195.    ,  85.    ,  30.    , 126.    , 150.    , 140.    ,\n",
       "       106.    , 149.    , 191.    , 115.    ,  55.    ,   8.    ,\n",
       "       165.    ,  75.    , 120.    ,  71.    ,  90.    , 180.    ,\n",
       "        60.    , 149.    ,  90.    , 110.    ,  80.    , 105.    ,\n",
       "       132.    , 105.    ,  75.    ,  90.    ,  90.    , 113.    ,\n",
       "       102.    ,  20.    ,  72.    ,  75.    , 105.    , 100.    ,\n",
       "        75.    ,  96.    ,  92.    , 100.    , 133.    ,  74.5   ,\n",
       "       450.    ,  12.    , 136.    ,  99.    , 300.    ,  55.    ,\n",
       "       110.    ,  65.    , 150.    ,  63.    , 100.    , 175.    ,\n",
       "       106.    , 120.    ,   2.5   ,  90.    ,  60.    , 105.    ,\n",
       "        81.5   , 160.    , 130.    , 220.    ,  95.    , 133.    ,\n",
       "        90.    , 120.    , 120.    , 120.    , 175.    ,  80.    ,\n",
       "       116.    , 220.    ,  95.    ,  50.    , 111.    ,  70.    ,\n",
       "       160.    ,  65.    , 200.    ,  35.396 ,  40.    ,  80.    ,\n",
       "       150.    , 225.    ,  90.    ,  75.    , 105.    , 200.    ,\n",
       "        74.    ,  85.    , 140.    ,  84.    , 135.    ,  91.    ,\n",
       "        90.    ,   8.    , 102.96  ,  95.    , 130.    ,  90.    ,\n",
       "        98.    ,  86.    ,  37.    , 160.    ,  80.    ,   3.85  ,\n",
       "       105.    , 100.    ,  80.    ,  63.    , 130.5   , 125.    ,\n",
       "       221.    , 100.    , 119.    , 100.    , 102.    ,   1.4   ,\n",
       "       105.    , 110.    ,   7.5   , 205.    , 240.    , 258.    ,\n",
       "       190.    , 210.    ,  75.    , 185.    ,  75.    ,  67.    ,\n",
       "        48.    , 119.    ,  63.    , 145.    , 120.    ,  60.    ,\n",
       "       102.5   , 182.    , 177.    , 180.    , 130.    , 340.    ,\n",
       "       190.    ,  70.    , 120.    ,  40.    ,  63.    ,  85.    ,\n",
       "       113.    ,  75.    , 130.    , 180.    , 350.    , 140.    ,\n",
       "       145.    , 275.    , 110.    ,  89.5   , 103.    ,  80.    ,\n",
       "       130.    , 175.    , 150.    ,  90.    , 108.    ,  70.    ,\n",
       "       180.939 , 170.    , 130.    , 155.    ,  63.    ,  66.    ,\n",
       "        42.    ,  60.    , 110.    , 145.    ,  65.    ,  90.    ,\n",
       "       160.    , 150.    ,  53.6   , 118.    ,  55.    , 130.    ,\n",
       "       200.    ,  64.    , 135.    ,  47.5   , 145.    , 112.    ,\n",
       "       150.    , 110.    , 250.    ,  85.    ,  94.    ,  79.0325,\n",
       "       177.    ,  99.    , 120.    ,  60.    ,  94.    , 115.    ,\n",
       "       130.    , 380.    , 175.    , 120.    , 110.    , 165.    ,\n",
       "       145.    ,  34.    , 125.    , 160.    ,  70.    ,  80.    ,\n",
       "        75.    , 180.    ,  76.    ,  87.5   , 165.    , 135.    ,\n",
       "       110.    ,  97.    , 110.    ,  83.    , 140.    , 110.    ,\n",
       "       100.    ,  87.    ,  47.    ,  64.    ,  52.    , 135.    ,\n",
       "       120.    , 190.    , 150.    ,  70.    ,  90.    ,  95.    ,\n",
       "        33.    ,  87.    , 162.    ,  66.    , 185.    , 120.    ,\n",
       "        28.    ,  78.78  ,  31.    , 129.    , 225.    ,  78.    ,\n",
       "        80.    ,  86.    ,  95.    , 135.    , 120.    , 115.    ,\n",
       "        87.    ,  25.    , 140.    ,  97.5   ,  70.001 , 141.    ,\n",
       "        60.    , 150.    , 110.    , 150.    , 120.    ,  85.    ,\n",
       "        80.    , 120.    ,  65.    , 115.    , 400.    , 128.    ,\n",
       "       165.    , 135.    ,  98.    ,  90.    ,  60.    , 250.    ,\n",
       "       110.    , 137.    ,  74.    ,  59.004 , 140.    ,  92.    ,\n",
       "       105.    ,  54.    ,   8.    ,  20.    ,  70.    ,  85.    ,\n",
       "       160.    , 131.    , 150.    , 116.    ,  56.    ,  85.    ,\n",
       "       150.    ,  90.    , 125.    , 150.    ,  79.    , 105.    ,\n",
       "       107.    ,  67.    , 120.    , 115.    ,  80.    , 180.    ,\n",
       "       140.    ,  61.    ,   2.5   , 107.    ,   9.92  ,  93.15  ,\n",
       "        10.    , 155.    , 100.3   ,  55.    ,  96.    , 220.    ,\n",
       "        90.    ,  81.    , 200.    , 110.    , 150.    ,  52.    ,\n",
       "        70.    , 147.    , 103.    , 122.    , 140.    , 120.    ,\n",
       "       180.    ,  88.    , 114.    , 180.    , 140.5   ,  70.    ,\n",
       "        55.    ,  80.    , 120.    , 140.    , 160.    ,  95.    ,\n",
       "       170.    ,  40.    ,  85.    , 100.    , 119.    , 113.    ,\n",
       "       110.    ,  90.    , 230.    ,  85.    , 120.    , 250.    ,\n",
       "        66.    , 125.    ,  75.    , 110.    ,  97.    , 358.956 ,\n",
       "       105.    , 100.    ,  72.    ,  85.    ,  66.    , 120.    ,\n",
       "        83.    ,  20.    , 250.    ,  85.    , 300.    , 130.    ,\n",
       "        95.    ,  85.    ,  60.    ,  65.    , 180.    , 136.    ,\n",
       "       150.    ,  62.    , 200.    ,  96.    ,  75.    ,  77.    ,\n",
       "       125.    , 105.    , 120.    , 140.    ,   8.48  ,  62.    ,\n",
       "        38.    , 110.    , 102.    , 135.    ,  91.    ,  80.    ,\n",
       "       115.    ,  53.    ,  75.    , 150.    ,  92.5   , 175.    ,\n",
       "       100.    ,  13.    ,  97.    , 135.    , 200.    , 130.    ,\n",
       "        85.    ,  67.    ,  52.    , 118.    , 150.    , 120.    ,\n",
       "       155.    ,  40.    ,  70.    ,  70.    , 138.    ,  93.    ,\n",
       "        80.    ,  90.    , 330.    ,  41.    ,  54.    ,  75.    ,\n",
       "       105.    , 100.    ,  75.    , 205.    , 100.    , 100.    ,\n",
       "       105.    , 175.    , 109.5   , 124.8   ,  82.5   ,  55.    ,\n",
       "       125.    , 160.    ,  51.    ,  80.    ,  76.5   , 100.    ,\n",
       "        50.    , 236.    , 190.    , 150.    , 135.    , 160.    ,\n",
       "        82.5   ,  80.    , 165.    , 147.    , 165.    ,  25.    ,\n",
       "       120.    ,  37.    ,  80.    ,  65.    ,  60.    ,  75.    ,\n",
       "        56.    ,  96.    ,  25.    ,  75.    ,  57.    , 450.    ,\n",
       "       110.    , 150.    ,  30.    , 100.    ,  85.    , 130.    ,\n",
       "       105.    ,  92.    , 135.    , 120.    ,  69.    ,   3.2   ,\n",
       "       100.    , 140.    , 130.    , 120.    , 165.    , 100.    ,\n",
       "       250.    , 194.6   ,  80.    , 110.    , 152.    , 180.    ,\n",
       "       135.    , 100.    , 145.    ,  88.    ,  65.    , 154.    ,\n",
       "       175.    , 185.    ,  20.    , 210.    ,  80.    , 159.    ,\n",
       "        30.    , 115.    ,  85.    , 150.    ,  70.    ,  85.    ,\n",
       "       108.    ,  78.5   ,  34.    , 170.    , 135.    , 103.    ,\n",
       "       120.    , 137.5   ,  50.    , 200.    , 130.    , 100.    ,\n",
       "        63.    ,  65.    ,  75.    , 140.    , 106.    , 165.    ,\n",
       "       107.    ,  68.    , 112.    ,  82.5   , 256.    , 125.    ,\n",
       "        90.    ,  90.    , 115.    , 110.    ,  60.    ,  74.1   ,\n",
       "        85.    , 150.    ,  65.    , 130.    , 142.    , 126.    ,\n",
       "       110.    , 150.    , 100.    , 120.    , 130.    , 120.    ,\n",
       "        12.    , 130.    , 120.    , 165.    ,  82.    , 165.    ,\n",
       "        15.    , 160.    , 150.    ,  55.    , 140.    ,  28.    ,\n",
       "        80.    , 155.    , 240.    ,  45.    , 150.    , 140.    ,\n",
       "         2.2   , 150.    ,  98.    ,   1.75  ,  56.    , 250.    ,\n",
       "        25.    ,  37.    ,   2.    , 180.    , 100.    ,  80.    ,\n",
       "         1.2   ,   7.    , 120.    ,  65.    ,  40.    ,   4.    ,\n",
       "       170.    ,  60.    ,  29.    ,   3.    , 100.    ,  91.    ,\n",
       "         6.    ,  50.    ,   7.5   , 150.    ,  12.    ,  11.    ,\n",
       "       140.    ,  32.4   ,  80.    ,   5.465 , 107.    ,  96.    ,\n",
       "       180.    , 160.    , 175.    ,  70.    , 250.    ,  20.    ,\n",
       "        25.    , 135.2   ,  50.    ,  40.    , 200.    ,   3.2   ,\n",
       "        29.5   ,  82.    ,  36.    ,  55.    ,  45.    ,  75.    ,\n",
       "        70.    , 200.    ,  40.    ,   1.6   , 140.    , 109.    ,\n",
       "        50.    ,   5.7   ,  60.    ,  30.    , 100.    ,  10.    ,\n",
       "        30.    ,  38.    ,  93.    ,  80.    ,   1.05  ,  27.    ,\n",
       "       120.    , 149.    ,  57.    ,  50.    ])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y.values\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c3d8b1",
   "metadata": {},
   "source": [
    "### Making predictions\n",
    "\n",
    "For any vector $\\vec{w} \\in \\mathbb{R}^{2}$, we can make predictions using\n",
    "\n",
    "$$\\vec{h} = X \\vec{w}$$\n",
    "\n",
    "Let's test it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06198de9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 99.11,  81.05,  92.15, 135.44,  94.85, 109.37, 106.25,  98.96,\n",
       "       116.42,  86.66,  97.97,  87.23, 103.49, 108.71,  82.04, 137.  ,\n",
       "        81.98,  82.73,  88.79,  91.76,  82.16, 151.52,  90.92, 119.06,\n",
       "       108.8 , 100.85,  90.11,  89.9 ,  86.75, 103.4 ,  83.42, 138.05,\n",
       "       141.02, 109.7 , 130.31, 173.96,  88.13, 123.23,  89.09, 105.62,\n",
       "        88.61, 138.32,  84.11,  99.68, 136.31, 127.22, 104.87, 109.88,\n",
       "        94.82, 130.97, 129.62,  85.34, 133.82,  89.  ,  88.01,  98.36,\n",
       "        91.88, 105.8 , 161.75,  94.88, 115.1 , 114.11,  88.64,  88.73,\n",
       "       117.71, 107.51, 100.1 ,  90.89,  97.37, 120.35, 134.81, 100.22,\n",
       "        93.47, 113.69,  97.55,  94.97,  94.19, 108.02,  95.63,  93.77,\n",
       "        95.12, 103.52, 104.75, 110.93, 104.84,  89.  ,  96.98,  82.85,\n",
       "        93.08, 146.72,  83.21, 131.03, 107.87,  95.78,  96.77,  89.06,\n",
       "        86.72,  97.31, 172.46,  94.13, 131.  , 103.43,  91.67,  89.51,\n",
       "        91.16,  95.48, 111.08,  85.67,  98.87,  95.84,  95.66, 109.07,\n",
       "       105.26, 109.16,  86.3 ,  82.91, 114.26,  88.43,  89.87, 171.23,\n",
       "       129.44,  94.16, 110.39,  91.52, 102.5 ,  90.98, 103.88, 116.9 ,\n",
       "       135.14, 105.32, 100.64,  81.86, 140.72,  91.19, 101.81,  89.18,\n",
       "       102.26, 172.25, 101.15,  85.13, 166.1 , 104.81,  84.47,  97.67,\n",
       "        96.77, 113.72, 101.81,  99.83,  87.92, 100.97,  84.68, 106.4 ,\n",
       "        89.63, 102.65, 155.57, 110.96,  89.57,  95.09, 117.74,  89.72,\n",
       "        87.74,  95.03,  97.04,  88.31, 159.05, 135.08, 152.72,  96.68,\n",
       "        89.06, 172.16,  90.23, 118.16,  92.81, 149.66, 174.5 ,  87.89,\n",
       "       135.2 ,  84.17,  87.08, 100.37,  98.57,  84.47, 143.42, 112.79,\n",
       "       123.44, 102.47,  83.18,  93.71,  81.95,  93.47,  99.47,  80.6 ,\n",
       "       105.59,  84.98,  98.36,  86.48, 119.33,  93.74, 103.82,  89.42,\n",
       "       103.4 ,  95.87, 150.95, 111.26, 139.7 ,  95.78, 171.86, 171.8 ,\n",
       "       135.53, 100.28,  86.9 , 160.46,  91.28, 107.81,  86.39,  85.22,\n",
       "        95.33, 114.2 , 148.16,  89.48, 170.09,  99.32,  85.1 ,  96.8 ,\n",
       "        96.86, 110.6 ,  81.32, 101.21,  85.04, 115.88, 114.56,  89.48,\n",
       "       141.11, 120.17, 129.89,  87.59, 124.01,  89.06,  83.75, 113.78,\n",
       "        84.92, 109.58, 101.9 ,  81.23, 125.15,  86.51, 101.24, 115.55,\n",
       "        80.66, 100.88, 136.34,  85.07,  96.11, 103.07, 174.62,  82.64,\n",
       "        96.65, 153.89, 109.25,  86.72, 114.08,  84.89, 107.96, 116.33,\n",
       "        98.  , 102.95, 116.51, 144.29, 172.07, 121.73,  82.97,  86.54,\n",
       "        95.21,  87.23,  90.47,  88.22, 136.34, 131.54,  80.54, 131.78,\n",
       "       116.48,  88.49,  81.59,  87.5 , 111.92, 132.29,  93.41,  95.66,\n",
       "        92.33, 127.19,  93.62,  85.91, 131.27,  85.46,  92.39, 134.3 ,\n",
       "        90.56,  97.85, 112.91, 120.8 ,  95.06, 131.12, 109.19,  85.64,\n",
       "        94.22, 102.14, 129.02,  91.52, 114.65,  80.57,  91.67, 114.05,\n",
       "        95.27,  85.25,  80.48, 173.21,  83.06,  86.3 ,  81.62,  81.5 ,\n",
       "        80.33, 144.47, 129.32, 133.16, 171.98, 141.02, 116.42, 104.9 ,\n",
       "       109.94, 141.23,  94.88, 117.77, 163.49,  89.3 , 108.29,  83.27,\n",
       "       138.53,  93.71, 114.59,  92.36, 103.16,  88.34, 102.23, 125.69,\n",
       "        96.89, 102.74,  81.23,  89.75,  93.2 ,  89.96, 102.59,  87.14,\n",
       "       172.91, 125.03,  83.93, 114.5 ,  88.67,  91.94,  81.89, 107.3 ,\n",
       "        87.32,  82.73,  94.04,  91.64, 102.98,  96.86,  92.99,  91.79,\n",
       "        89.84,  92.51, 116.9 ,  85.97,  96.86, 108.02, 102.89,  99.35,\n",
       "       113.87,  89.27, 103.16,  91.79, 143.84, 100.49, 103.49, 107.33,\n",
       "        94.88,  84.71, 101.81,  84.14, 107.6 , 166.13,  99.71,  87.38,\n",
       "       104.75,  82.85,  93.02,  85.16,  95.99, 139.88, 111.2 , 134.6 ,\n",
       "        95.93, 106.91,  87.44,  86.42,  97.4 ,  85.49, 136.43,  88.85,\n",
       "        97.73,  88.4 ,  87.35,  82.22,  92.21,  98.48, 128.  ,  88.88,\n",
       "       170.6 ,  82.43,  83.99,  94.1 ,  95.96, 116.09,  84.86,  83.06,\n",
       "        93.86, 114.23,  85.49, 142.04, 138.89, 135.56, 125.6 ,  95.81,\n",
       "        96.17,  85.25, 104.93, 154.46,  80.87,  93.89,  81.26,  99.23,\n",
       "        82.58, 126.47,  92.33, 102.92, 104.72,  90.53,  98.39,  88.49,\n",
       "       133.34,  94.28, 134.03, 110.18, 114.44,  94.58,  91.64,  81.02,\n",
       "       101.21, 101.87, 115.76, 124.46, 157.79, 134.42, 136.01, 118.58,\n",
       "        84.68, 106.58,  87.8 ,  88.04,  83.93,  97.76,  91.52, 101.12,\n",
       "       114.62, 102.35, 101.72, 130.88,  91.88, 152.54, 109.55,  99.17,\n",
       "       103.61,  89.81,  99.95,  80.93, 110.87, 106.85,  94.19,  92.81,\n",
       "       122.48, 141.71, 141.95, 118.1 , 129.65, 143.39,  81.38,  97.79,\n",
       "        84.08, 100.94, 139.73, 122.84,  83.72,  85.22, 126.32,  98.96,\n",
       "       136.49, 132.26, 134.27, 154.4 ,  96.08,  84.23,  98.48, 110.24,\n",
       "       105.86, 128.78,  91.31, 105.29, 102.89, 171.38,  81.5 , 100.19,\n",
       "        87.62, 101.75, 171.71, 132.2 ,  91.58,  87.68, 114.47, 109.67,\n",
       "       106.46, 165.29, 127.46,  85.76,  94.94,  92.84,  99.35, 122.66,\n",
       "        93.05,  85.49,  98.9 ,  90.5 , 140.42, 167.93, 132.2 ,  92.84,\n",
       "       110.42, 104.87,  97.46,  83.33,  86.15, 144.23,  90.32,  82.79,\n",
       "        82.16,  96.29,  82.82, 112.76, 124.94, 129.68,  87.23, 110.54,\n",
       "        85.67,  90.68, 109.4 ,  91.25,  94.37,  87.29, 118.67,  89.72,\n",
       "        97.1 ,  88.13, 116.36,  87.23,  91.7 ,  94.61, 170.69,  87.77,\n",
       "        98.09,  90.65, 125.21,  86.48,  87.53,  94.55,  88.1 ,  84.89,\n",
       "        83.9 , 107.48, 109.67,  91.79,  97.16,  98.33,  94.22, 116.63,\n",
       "       141.86,  93.47,  82.94,  98.18,  84.92,  92.  ,  90.05,  89.  ,\n",
       "        92.6 , 126.26, 104.51, 129.5 ,  83.9 ,  89.48, 101.33, 100.19,\n",
       "        95.36, 117.35, 115.7 ,  96.41,  87.77, 137.27,  88.37,  84.77,\n",
       "        80.54, 116.03,  82.52, 155.93, 115.25, 110.  , 155.45, 133.34,\n",
       "       103.88, 108.53,  91.25,  96.11, 113.84,  90.11, 100.61,  97.97,\n",
       "       156.08,  94.07,  90.65,  85.97,  86.63, 124.82,  99.41,  99.95,\n",
       "        92.78, 107.96,  82.91,  92.33, 171.26, 115.07,  87.26, 165.8 ,\n",
       "       139.43,  97.1 ,  83.81, 105.26,  96.92,  90.05,  90.14, 102.98,\n",
       "        84.17,  94.91,  98.6 , 133.49,  84.5 ,  96.65, 172.16,  94.34,\n",
       "        88.49,  87.98, 124.19,  97.88, 118.4 , 133.28, 100.7 ,  83.66,\n",
       "       104.96,  91.22,  94.85,  93.65, 166.85, 101.72,  84.53,  90.71,\n",
       "        80.9 , 108.56, 117.5 ,  95.9 , 150.17,  84.23,  89.69, 100.43,\n",
       "        82.97, 120.95,  86.54, 165.32,  88.1 ,  93.98, 130.1 , 123.05,\n",
       "        85.76, 107.75,  85.79, 115.76,  97.88, 130.85,  90.02,  91.46,\n",
       "       100.76,  81.38, 118.85, 101.6 ,  93.71, 106.07,  91.49, 141.44,\n",
       "       109.91, 110.03, 106.79, 100.01, 102.47, 103.91, 113.48, 130.31,\n",
       "       105.95,  87.47, 166.49,  91.19,  85.64,  81.68, 131.66,  98.51,\n",
       "       116.93, 105.14,  87.68,  99.29,  88.61, 100.37,  87.47, 128.03,\n",
       "       109.61,  87.47,  90.92,  84.89, 117.17, 103.31,  81.56, 131.99,\n",
       "       167.42,  91.58,  97.97,  90.56, 168.11, 113.36,  90.77,  81.98,\n",
       "        85.73, 119.33, 175.01, 107.93,  89.84,  82.4 ,  81.38,  92.03,\n",
       "       113.33,  98.54, 102.32,  91.49, 130.67,  83.72,  86.66,  94.97,\n",
       "        90.65,  85.04,  84.44, 106.13, 103.4 , 139.16, 143.39, 104.  ,\n",
       "        93.92, 110.33,  84.92,  87.05, 107.81,  86.39,  84.08, 103.52,\n",
       "        88.94, 101.45,  92.33, 141.95, 102.56, 139.82, 101.06,  93.47,\n",
       "        89.09, 102.32,  91.82, 131.09, 116.51,  91.82,  88.43,  81.11,\n",
       "        86.42,  81.44,  96.65,  90.74,  85.67,  94.58,  88.97,  96.05,\n",
       "        83.39, 170.15,  94.43, 171.65,  84.29, 114.14, 104.87, 119.99,\n",
       "        86.12,  80.39, 105.47, 101.93,  96.71, 170.24,  85.55,  88.7 ,\n",
       "       169.67, 115.79, 167.75,  98.27, 130.61,  89.84,  84.35,  94.76,\n",
       "        99.08, 130.46, 114.38,  87.98, 121.28, 133.13,  96.38, 154.52,\n",
       "       105.47, 135.23, 104.51, 160.04,  83.9 , 114.29,  90.26,  95.75,\n",
       "        89.69, 138.17,  97.97,  87.2 , 107.54,  99.23, 120.2 , 135.65,\n",
       "       133.1 ,  80.9 ,  88.1 , 125.33,  93.32, 100.76,  89.57, 117.62,\n",
       "        92.93, 140.24, 129.14, 105.23,  92.66, 124.61, 130.28,  84.95,\n",
       "        92.09, 101.51, 129.74, 109.64,  92.51,  96.98, 101.36,  99.32,\n",
       "        91.58,  92.57, 100.94, 107.21,  93.35,  91.19,  98.93, 103.19,\n",
       "       116.36,  90.17,  97.16, 114.14, 107.36, 110.87,  91.94, 102.35,\n",
       "       134.48,  87.68,  90.92, 110.21,  96.5 , 103.97, 170.93, 102.35,\n",
       "        96.62,  89.27,  89.51, 169.97, 106.01,  86.69, 135.8 , 147.08,\n",
       "        89.33, 140.9 , 102.05, 106.43,  94.67,  95.24,  98.99,  97.01,\n",
       "        89.51, 139.46,  98.6 , 101.33,  88.7 , 133.82, 139.13, 103.13,\n",
       "        90.32, 100.37, 110.51,  83.36,  93.23, 151.31,  90.5 ,  98.21,\n",
       "        95.93, 130.58,  86.93,  97.91, 169.25, 141.29, 146.03,  95.9 ,\n",
       "        89.36, 137.03, 143.99, 148.4 , 168.02, 126.11, 142.49,  87.41,\n",
       "       117.17, 112.94, 134.9 , 102.74,  87.62,  91.4 , 168.02,  90.11,\n",
       "        89.57,  99.71,  98.27,  87.62,  93.08,  88.55,  89.54, 164.24,\n",
       "        86.66, 125.96, 134.33, 171.8 , 103.1 ,  83.57,  80.6 ,  80.6 ,\n",
       "       148.76,  92.9 ,  94.76, 102.26, 123.86,  97.07,  80.75,  95.21,\n",
       "       104.72,  99.38, 128.81,  81.68])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X @ np.array([80, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2071aca8",
   "metadata": {},
   "source": [
    "Our goal is to get the above array as close to `y` as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23cf0f2",
   "metadata": {},
   "source": [
    "### Implementing the solution\n",
    "\n",
    "We claimed that the vector $\\vec{w}$ that minimizes\n",
    "\n",
    "$$R_{sq}(\\vec{w}) = \\frac{1}{n} || \\vec{y} - X \\vec{w} ||^2$$\n",
    "\n",
    "is\n",
    "\n",
    "$$\\vec{w}^* = (X^TX)^{-1}X^T\\vec{y}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6da75b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def least_squares(X, y):\n",
    "    # YOUR IMPLEMENTATION IS HERE\n",
    "    return np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c90ab783",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_star = least_squares(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d815dfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([80.79258094,  3.22297875])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_star"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311673aa",
   "metadata": {},
   "source": [
    "What if I have 10 years of experience – what should I expect my salary to be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f20d51b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113.0223684888939"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([1, 10]) @ w_star"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aacfe8c5",
   "metadata": {},
   "source": [
    "Note that these match the intercept and slope using our manual formulas!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc74d5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation(x, y):\n",
    "    # YOUR IMPLEMENTATION IS HERE\n",
    "    numerator = np.sum((x - np.mean(x)) * (y - np.mean(y)))\n",
    "    denominator_x = np.sum((x - np.mean(x))**2)\n",
    "    denominator_y = np.sum((y - np.mean(y))**2)\n",
    "    correlation_coefficient = numerator / np.sqrt(denominator_x * denominator_y)\n",
    "    return correlation_coefficient\n",
    "\n",
    "def slope(x, y):\n",
    "    # YOUR IMPLEMENTATION IS HERE\n",
    "    numerator = np.sum((x - np.mean(x)) * (y - np.mean(y)))\n",
    "    denominator = np.sum((x - np.mean(x))**2)\n",
    "    slope_value = numerator / denominator\n",
    "    return slope_value\n",
    "\n",
    "def intercept(x, y):\n",
    "    # YOUR IMPLEMENTATION IS HERE\n",
    "    m = slope(x, y)\n",
    "    intercept_value = np.mean(y) - m * np.mean(x)\n",
    "    return intercept_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9708bf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80.79258094057926"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intercept(X[:, 1], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cbad712c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.222978754831467"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slope(X[:, 1], y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d148df",
   "metadata": {},
   "source": [
    "The intercept and slope must be the same in both ways of calculation (either via closed-form formula with pseudo-inverse or formula with correlation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722b8915",
   "metadata": {},
   "source": [
    "Now, solve the Linear Regression with Gradient Descent! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "360af7e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80.79234696555814\n",
      "3.2229941864546667\n"
     ]
    }
   ],
   "source": [
    "def gradient_descent_linear_regression(X, y, alpha=0.01):\n",
    "    w = np.zeros(X.shape[1])\n",
    "    n = len(y)\n",
    "    threshold = 1e-6 \n",
    "    \n",
    "    while True:\n",
    "        y_pred = np.dot(X, w)\n",
    "#         print(y_pred)\n",
    "        gradient = -(1/n) * np.dot(X.T, (y - y_pred))\n",
    "#         print(gradient)\n",
    "        w -= alpha * gradient\n",
    "#         print(w)\n",
    "        \n",
    "        if np.linalg.norm(alpha * gradient) < threshold:\n",
    "            break\n",
    "    \n",
    "    return w\n",
    "\n",
    "coefficients = gradient_descent_linear_regression(X, y)\n",
    "intercept = coefficients[0]\n",
    "slopes = coefficients[1]\n",
    "print(intercept)\n",
    "print(slopes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8df6f5d",
   "metadata": {},
   "source": [
    "Now, solve the Linear Regression with built-in libary sklearn. Check https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "333783b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80.79258094057927\n",
      "3.2229787548314657\n"
     ]
    }
   ],
   "source": [
    "# YOUR IMPLEMENTATION IS HERE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "reg = LinearRegression().fit(X, y)\n",
    "\n",
    "# Get the coefficients\n",
    "intercept = reg.intercept_\n",
    "coefficients = reg.coef_\n",
    "\n",
    "print(intercept)\n",
    "print(coefficients[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5b713d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
